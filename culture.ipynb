{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_floats = np.random.uniform(-1, 1, size=(3,10000))\n",
    "random = np.random.randint(9, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['red'] = random_floats[0]\n",
    "df['nir'] = random_floats[1]\n",
    "df['swir'] = random_floats[2]\n",
    "df['class'] = random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_filtered_new.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_info = {\n",
    "  'Пшеница - 231 тонн':                {'value':0, 'color': '#CCFF66'},\n",
    "  'Не найдено - 10 тонн':              {'value':1, 'color': '#000000'},\n",
    "  'Подсолнечник - 0 тонн':             {'value':2, 'color': '#CC9933'},\n",
    "  'Хлопок - 1 тонн':                   {'value':3, 'color': '#CC0000'},\n",
    "  'Табак - 0 тонн':                    {'value':4, 'color': '#FF00FF'},\n",
    "  'Сахарная свекла - 0 тонн':          {'value':5, 'color': '#9900FF'},\n",
    "  'Капуста - 0 тонн':                  {'value':6, 'color': '#6633CC'},\n",
    "  'Свекла - 0 тонн':                   {'value':7, 'color': '#3300FF'},\n",
    "  'Моpковь - 0 тонн':                  {'value':8, 'color': '#33FFCC'},\n",
    "  'Лук - 0 тонн':                      {'value':9, 'color': '#00FF00'},\n",
    "  'Кукуруза - 0 тонн':                 {'value':10, 'color': '#99CC00'},\n",
    "  'Зелень - 0 тонн':                   {'value':11, 'color': '#99CCFF'},\n",
    "  'Перец - 0 тонн':                    {'value':12, 'color': '#CCCCCC'},\n",
    "  'Огурцы - 0 тонн':                   {'value':13, 'color': '#CC99FF'},\n",
    "  'Помидоры - 0 тонн':                 {'value':14, 'color': '#CC9999'},\n",
    "  'Чеснок - 0 тонн':                   {'value':15, 'color': '#FF9900'},\n",
    "  'Редька - 0 тонн':                   {'value':16, 'color': '#CC3300'},\n",
    "  'Ячмень - 350 тонн':                 {'value':17, 'color': '#6600CC'},\n",
    "  'Рис - 0 тонн':                      {'value':18, 'color': '#FFFF00'},\n",
    "  'Овес - 420 тонн':                   {'value':19, 'color': '#66CC99'},\n",
    "}\n",
    "\n",
    "classes = {x : y.get('value') for x, y in classe_info.items()}\n",
    "\n",
    "classes_colors = [y.get('color') for x, y in classe_info.items()]\n",
    "\n",
    "features = ['red', 'nir', 'swir']\n",
    "n_features = len(features)\n",
    "\n",
    "sequence_size = 30\n",
    "\n",
    "model_dir = './logs'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "url = \"df_filtered.csv\"\n",
    "data = pd.read_csv(url)\n",
    "# data = data.drop(['date', 'id'], axis=1)\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print('data shape = ',data.shape)\n",
    "print('X_train, y_train shape = ', X_train.shape, y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for CUDA-enabled GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using {device} for training.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Move data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(X_train).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "\n",
    "X_test = torch.Tensor(X_test).to(device)\n",
    "y_test = torch.LongTensor(y_test).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderLSTM(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "    super(EncoderDecoderLSTM, self).__init__()\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.encoder_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "    self.decoder_lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "    _, (hn, cn) = self.encoder_lstm(x.unsqueeze(1), (h0, c0))  # Add a dimension for the sequence length\n",
    "    out, _ = self.decoder_lstm(hn.transpose(0, 1), (hn, cn))  # Transpose hn to match the expected input shape\n",
    "    out = self.fc(out.squeeze(1))  # Squeeze the sequence length dimension\n",
    "    out = self.relu(out)  # Apply ReLU activation function to the output of the linear layer\n",
    "\n",
    "    return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function and optimizer\n",
    "device = torch.device(\"cpu\")\n",
    "model = EncoderDecoderLSTM(input_dim, hidden_dim, num_layers, output_dim).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Initialize empty lists for storing the loss and time\n",
    "train_loss = []\n",
    "train_time = []\n",
    "\n",
    "# Enable interactive mode in matplotlib\n",
    "# plt.ion()\n",
    "\n",
    "# Create plot for training loss\n",
    "# fig, ax = plt.subplots(figsize=(15, 6))\n",
    "# ax.set_xlabel(\"Epoch\")\n",
    "# ax.set_ylabel(\"Loss\")\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute and store the training loss and time\n",
    "    train_loss.append(loss.item())\n",
    "    train_time.append(time.time() - start_time)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Time: {train_time[-1]:.2f}s')\n",
    "\n",
    "    # Update plot for training loss\n",
    "#     ax.plot(train_loss, '-o')\n",
    "#     ax.set_xlim(1, len(train_loss))\n",
    "#     ax.set_ylim(min(train_loss), max(train_loss))\n",
    "#     clear_output(wait=True)\n",
    "#     display(fig)\n",
    "#     plt.pause(0.01)\n",
    "\n",
    "# # Show the final plot\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        # print(inputs)\n",
    "        # print(labels)\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Save the model checkpoint\n",
    "# torch.save({'model_state_dict': model.state_dict()}, 'model_checkpoint.pt')\n",
    "torch.save(model,'cpu2.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on custom photo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get grom 3 tiff(red, nir swir) one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Open the TIFF files and extract the data as NumPy arrays\n",
    "with rasterio.open('./B04.tif') as src:\n",
    "    red = src.read(1)\n",
    "\n",
    "with rasterio.open('./B8A.tif') as src:\n",
    "    nir = src.read(1)\n",
    "\n",
    "with rasterio.open('./B11.tif') as src:\n",
    "    swir = src.read(1)\n",
    "\n",
    "# Combine the NumPy arrays for the different bands into a single NumPy array\n",
    "data = np.dstack((red, nir, swir))\n",
    "data[:,:,1].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_array = data.astype(np.float32)\n",
    "# float_array = float_array[:-5400, :-5400]\n",
    "\n",
    "# input_tensor_test = torch.from_numpy(float_array).float()\n",
    "input_tensor_test = torch.from_numpy(float_array)\n",
    "\n",
    "print(input_tensor_test.shape)\n",
    "tensor_2d = input_tensor_test.reshape(-1, 3)\n",
    "\n",
    "# Print the shape of the reshaped tensor\n",
    "print(tensor_2d)\n",
    "tensor_2d.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transform to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X2 = scaler.fit_transform(tensor_2d)\n",
    "# Move data to GPU\n",
    "X2 = torch.Tensor(X2).to(device)\n",
    "X2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output_tensor = model.forward(X2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation predicted data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### from torch tensor to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_tensor = torch.argmax(output_tensor, dim=1)\n",
    "print('argmax_tensor shape = ', argmax_tensor.shape)\n",
    "\n",
    "tensor_cpu = argmax_tensor.cpu()\n",
    "\n",
    "argmax_array = tensor_cpu.numpy()\n",
    "\n",
    "array_2d = argmax_array.reshape(data[:,:,1].shape)\n",
    "\n",
    "print('array_2d shape = ', array_2d.shape)\n",
    "print('array_2d', array_2d)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization on predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import colors \n",
    "\n",
    "keys = list(classe_info.keys())\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "cmap = colors.ListedColormap(classes_colors)\n",
    "plt.imshow(array_2d, cmap=cmap)\n",
    "plt.legend(title=\"Наименование и урожайность культуры\", bbox_to_anchor =(1, 1.01), loc='upper left')\n",
    "plt.axis('off')\n",
    "plt.title('Культура')\n",
    "plt.savefig('out.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one culture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "array_2d = np.array(array_2d)\n",
    "array_2d = array_2d.astype(int)\n",
    "\n",
    "# Get the mode of the array\n",
    "mode_value = mode(array_2d, axis=None)[0]\n",
    "\n",
    "# Fill the array with the mode value\n",
    "filled_array = np.full(array_2d.shape, mode_value)\n",
    "filled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import colors \n",
    "\n",
    "keys = list(classe_info.keys())\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "cmap = colors.ListedColormap(classes_colors)\n",
    "plt.imshow(array_2d, cmap=cmap)\n",
    "plt.legend(title=\"Наименование и урожайность культуры\", bbox_to_anchor =(1, 1.01), loc='upper left')\n",
    "plt.axis('off')\n",
    "plt.title('Культура')\n",
    "plt.savefig('out.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if GPU is available\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Load the saved model checkpoint\n",
    "# checkpoint = torch.load('model_checkpoint.pt', map_location=device)\n",
    "\n",
    "# # Define the model architecture\n",
    "# model = EncoderDecoderLSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "# # Load the saved model parameters\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# # Move the model to the GPU\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Load the saved model checkpoint\n",
    "checkpoint = torch.load('model_checkpoint.pt', map_location=device)\n",
    "\n",
    "# Define the model architecture\n",
    "model = EncoderDecoderLSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "# Load the saved model parameters\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move the model and its parameters back to the CPU\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# X2 = scaler.fit_transform(tensor_2d)\n",
    "# # Move data to GPU\n",
    "# X2 = torch.Tensor(X2).to(device)\n",
    "# X2.shape\n",
    "\n",
    "# Move data to GPU\n",
    "device = torch.device('cpu')\n",
    "X2 = torch.Tensor(X2)\n",
    "\n",
    "# Do some processing on the GPU\n",
    "\n",
    "# Move the tensor back to the CPU\n",
    "X2 = X2.cpu()\n",
    "\n",
    "# Convert the tensor back to a numpy array\n",
    "X2 = X2.numpy()\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax_tensor = torch.argmax(output_tensor, dim=1)\n",
    "# print('argmax_tensor shape = ', argmax_tensor.shape)\n",
    "\n",
    "# tensor_cpu = argmax_tensor.cpu()\n",
    "\n",
    "# argmax_array = tensor_cpu.numpy()\n",
    "\n",
    "# array_2d = argmax_array.reshape(data[:,:,1].shape)\n",
    "\n",
    "# print('array_2d shape = ', array_2d.shape)\n",
    "# print('array_2d', array_2d)\n",
    "\n",
    "\n",
    "\n",
    "# Move the tensor from GPU to CPU\n",
    "argmax_tensor_cpu = argmax_tensor.cpu()\n",
    "\n",
    "# Convert the tensor to a numpy array\n",
    "argmax_array = argmax_tensor_cpu.numpy()\n",
    "\n",
    "# Reshape the array to the desired shape\n",
    "array_2d = argmax_array.reshape(data[:,:,1].shape)\n",
    "\n",
    "print('array_2d shape = ', array_2d.shape)\n",
    "print('array_2d', array_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
