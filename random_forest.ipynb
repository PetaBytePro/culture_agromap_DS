{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./data/dataSet_Culture_06102023-POINT.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from 'Analysis Date'\n",
    "df['year'] = df['Analysis Date'].apply(lambda x: x.split('-')[0])\n",
    "\n",
    "df['polygon_x'] = df['polygon'].apply(lambda x: x['x'])\n",
    "df['polygon_y'] = df['polygon'].apply(lambda x: x['y'])\n",
    "df['month'] = df['Analysis Date'].apply(lambda x: x.split('-')[1])\n",
    "df['day'] = df['Analysis Date'].apply(lambda x: x.split('-')[2])\n",
    "\n",
    "df['vegetation'] = (df['indextype'] == 'NDVI') & (df['averagevalue'] >= 0.15)\n",
    "df = df.drop(['polygon', 'soil_id'] , axis = 1)\n",
    "\n",
    "# Modify the 'combined' column to include year\n",
    "df['combined'] = df['polygon_x'].astype(str) + '_' + df['polygon_y'].astype(str) + '_' + df['year'].astype(str)\n",
    "\n",
    "# Assign unique ID based on the grouped column\n",
    "df['id'] = df.groupby('combined').ngroup() + 1\n",
    "\n",
    "# Drop the combined column and other temporary columns\n",
    "df = df.drop(columns=['combined', 'polygon_x', 'polygon_y', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['indextype'] == 'NDVI']\n",
    "df = df.drop(columns=['indextype', 'year contour', 'month', 'day', 'vegetation', 'type_culture_name'])\n",
    "df = df.rename(columns={'culture_name': 'class'})\n",
    "df = df.rename(columns={'averagevalue': 'red'})\n",
    "df = df.rename(columns={'Analysis Date': 'date'})\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 16, 21,  4, 11, 13,  7, 20, 18,  3,  0,  5, 17,  8, 12, 10, 15,\n",
       "       14,  6,  1, 19,  9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'class'. \n",
    "df['class']= label_encoder.fit_transform(df['class']) \n",
    "df['district_name']= label_encoder.fit_transform(df['district_name']) \n",
    "df['soil_name']= label_encoder.fit_transform(df['soil_name']) \n",
    "df['class'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to multiple columns (year, month, day)\n",
    "df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "df['day'] = pd.to_datetime(df['date']).dt.day\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# Splitting data    \n",
    "X = df.drop(['class', 'id', 'year', 'day'], axis=1) \n",
    "y = df['class']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table\n",
    "pivot_df = df.pivot_table(index='id', columns='month', values='red', aggfunc='mean')\n",
    "\n",
    "# Fill NaN values (assuming you want to fill with zeros, adjust if needed)\n",
    "# pivot_df = pivot_df.fillna(0)\n",
    "\n",
    "# Rename columns as needed\n",
    "pivot_df.columns = [f'red_{col}_month' for col in pivot_df.columns]\n",
    "\n",
    "# Reset the index so 'id' becomes a column\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "# Assuming each 'id' has a unique 'class', get the 'class' value for each 'id' and add to the pivot dataframe\n",
    "pivot_df['class'] = pivot_df['id'].map(df.drop_duplicates(subset='id').set_index('id')['class'])\n",
    "pivot_df['elevation_contour'] = pivot_df['id'].map(df.drop_duplicates(subset='id').set_index('id')['elevation_contour'])\n",
    "pivot_df['district_name'] = pivot_df['id'].map(df.drop_duplicates(subset='id').set_index('id')['district_name'])\n",
    "pivot_df['soil_name'] = pivot_df['id'].map(df.drop_duplicates(subset='id').set_index('id')['soil_name'])\n",
    "\n",
    "# Reordering columns\n",
    "pivot_df = pivot_df[['red_4_month', 'red_5_month', 'red_6_month', 'red_8_month', 'red_9_month', 'id', 'elevation_contour', 'district_name', 'soil_name', 'class']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X = pivot_df.drop(['id', 'class'], axis=1)  # Features excluding 'id' and 'class'\n",
    "y = pivot_df['class']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = y.value_counts()\n",
    "single_sample_classes = class_counts[class_counts == 1].index\n",
    "filter_mask = ~y.isin(single_sample_classes)\n",
    "X = X[filter_mask]\n",
    "y = y[filter_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your features in X and classes in y\n",
    "\n",
    "unique_classes = set(y)\n",
    "binary_classifications = {}\n",
    "evaluation_metrics = {}\n",
    "trained_classifiers = {}\n",
    "\n",
    "for u_class in unique_classes:\n",
    "    # Convert the labels for one-vs-all classification\n",
    "    y_train_binary = [1 if label == u_class else 0 for label in y_train]\n",
    "    y_test_binary = [1 if label == u_class else 0 for label in y_test]\n",
    "    \n",
    "    # Train a Random Forest classifier\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train_binary)\n",
    "    trained_classifiers[u_class] = clf\n",
    "    \n",
    "    # Predict on the test set\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    binary_classifications[u_class] = predictions\n",
    "    \n",
    "    # Evaluate the classifier's performance\n",
    "    accuracy = accuracy_score(y_test_binary, predictions)\n",
    "    \n",
    "    # Check if there's only one unique class in y_test_binary\n",
    "    if len(set(y_test_binary)) == 1:\n",
    "        precision = recall = f1 = auc = np.nan\n",
    "    else:\n",
    "        precision = precision_score(y_test_binary, predictions)\n",
    "        recall = recall_score(y_test_binary, predictions)\n",
    "        f1 = f1_score(y_test_binary, predictions)\n",
    "        auc = roc_auc_score(y_test_binary, predictions)\n",
    "    \n",
    "    evaluation_metrics[u_class] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC-AUC': auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_batch = {u_class: [] for u_class in trained_classifiers.keys()}\n",
    "\n",
    "for u_class, clf in trained_classifiers.items():\n",
    "    probs = clf.predict_proba(X_test)[:, 1]\n",
    "    probabilities_batch[u_class] = probs\n",
    "\n",
    "final_class_predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    final_class = max(probabilities_batch, key=lambda x: probabilities_batch[x][i])\n",
    "    final_class_predictions.append(final_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(final_class_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_batch = {u_class: [] for u_class in trained_classifiers.keys()}\n",
    "\n",
    "for u_class, clf in trained_classifiers.items():\n",
    "    probs = clf.predict_proba(X_train)[:, 1]\n",
    "    probabilities_batch[u_class] = probs\n",
    "\n",
    "final_class_predictions = []\n",
    "for i in range(len(X_train)):\n",
    "    final_class = max(probabilities_batch, key=lambda x: probabilities_batch[x][i])\n",
    "    final_class_predictions.append(final_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(final_class_predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red_4_month</th>\n",
       "      <th>red_5_month</th>\n",
       "      <th>red_6_month</th>\n",
       "      <th>red_8_month</th>\n",
       "      <th>red_9_month</th>\n",
       "      <th>elevation_contour</th>\n",
       "      <th>district_name</th>\n",
       "      <th>soil_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>707.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>720.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>868.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.061</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>704.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>687.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.139</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>712.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    red_4_month  red_5_month  red_6_month  red_8_month  red_9_month  \\\n",
       "0         0.038       0.0680        0.167       0.0780       0.0550   \n",
       "1         0.016       0.0606        0.082       0.0920       0.0960   \n",
       "2         0.037       0.0560        0.110       0.0950       0.1856   \n",
       "3         0.004       0.0190        0.020       0.0090       0.0110   \n",
       "4         0.086       0.0880        0.341       0.6940       0.4720   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "95        0.061       0.1410        0.274       0.1608       0.1850   \n",
       "96        0.033       0.0860        0.192       0.0920       0.0840   \n",
       "97        0.115       0.1060        0.059       0.0380       0.0550   \n",
       "98        0.006       0.0180        0.017       0.1670       0.1776   \n",
       "99        0.139       0.2050        0.270       0.6205       0.6440   \n",
       "\n",
       "    elevation_contour  district_name  soil_name  \n",
       "0               707.0            4.0       10.0  \n",
       "1               720.0            4.0       10.0  \n",
       "2               600.0            5.0       11.0  \n",
       "3               868.0            1.0       10.0  \n",
       "4               937.0            1.0       10.0  \n",
       "..                ...            ...        ...  \n",
       "95              704.0            5.0        9.0  \n",
       "96             1544.0            2.0        4.0  \n",
       "97              687.0            5.0        1.0  \n",
       "98              897.0            0.0        3.0  \n",
       "99              712.0            7.0       10.0  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
